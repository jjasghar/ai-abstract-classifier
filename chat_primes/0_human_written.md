# Open Source AI and InstructLab 

## Abstract
In a world of fast-moving AI adoption, the big players want you to play with their versions of AI. The problem, though, is that their AI is usually built in a way that is closed off from the eyes of our tech community, with little or no oversight for choices and legal grey areas for usage and adoption.  What if I told you there was a way to get the best of both worlds? An AI solution that can be externally verified and trusted legally, and we want you, yes, you, to join us in building a genuinely transparent AI solution.  This is what the Granite and Granite-Code foundational models are. You can read the paper on how the model was initially trained and have IBM's lawyers back up claims made from using Granite or Granite-Code usage. Can your other AI providers say that? Will they give you the design documents on how they built it from the ground up? Or will they put their lawyers behind your usage of their AI? Would you put your business at risk of using something like this when the legal area is so grey and ever-changing?  But that's only a point in time; you also need to add skills and knowledge to the ever-growing AI system, which is where InstructLab comes into play. During this presentation/workshop, we will be showing you why you should care about Open Source AI, teach you how to leverage a purely Open Source AI for a local 'co-pilot' like experience, and then help train the Granite foundational model with new knowledge, giving you the skills to help build a genuinely transparent AI.  Join us and learn with us. We want to build a future of transparency and legal protection for AI engineers.
    